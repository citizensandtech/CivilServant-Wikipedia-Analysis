{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Per-Language Counts of Thankers and Superthankers\n",
    "July 25, 2019\n",
    "\n",
    "Columns needed for MailChimp:\n",
    "* user_email: email address for the account\n",
    "* anonymized_id: anonymized ID\n",
    "* user_name: Wikipedia username\n",
    "* lang: language Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, os, glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Superthankers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/civilservant/Tresors/CivilServant/projects/wikipedia-integration/gratitude-study/Data Drills/thanker_hardlaunch/\"\n",
    "superthankers = {\n",
    "    \"fa\":[],\n",
    "    \"de\":[],\n",
    "    \"pl\":[]\n",
    "}\n",
    "stl = []\n",
    "with open(os.path.join(data_dir, \"SuperThankers-07.25.2019.csv\")) as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        superthankers[row['wiki']].append(row['\\ufeffusername'])\n",
    "\n",
    "liason_usernames = []\n",
    "with open(os.path.join(data_dir, \"liasons-07.29.2019.csv\")) as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        liason_usernames.append(row['user_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a lookup table from consent records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "id_key = dict()\n",
    "\n",
    "for lang in superthankers.keys():\n",
    "    with open(os.path.join(data_dir, \"julia_input\", lang + \"_consent_6_26_clean.csv\")) as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            id_key[row['ID']] = {\n",
    "                \"user_name\": row['user_name'],\n",
    "                \"user_email\": row['user_email']} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load merged survey and observational data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fa PARTICIPATION COUNTS\n",
      "\n",
      "  53 thankers\n",
      "  2 superthankers (that consented)\n",
      "  DIAGNOSTIC:\n",
      "    fa Matched Keys: 55\n",
      "    fa Unmatched Keys: 0\n",
      "    53 Unique anonymized IDs\n",
      "\n",
      "de PARTICIPATION COUNTS\n",
      "\n",
      "  294 thankers\n",
      "  5 superthankers (that consented)\n",
      "  DIAGNOSTIC:\n",
      "    de Matched Keys: 299\n",
      "    de Unmatched Keys: 0\n",
      "    294 Unique anonymized IDs\n",
      "\n",
      "pl PARTICIPATION COUNTS\n",
      "\n",
      "  64 thankers\n",
      "  2 superthankers (that consented)\n",
      "  DIAGNOSTIC:\n",
      "    pl Matched Keys: 66\n",
      "    pl Unmatched Keys: 0\n",
      "    64 Unique anonymized IDs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thanker_ids = []\n",
    "\n",
    "for lang in superthankers.keys():\n",
    "    matched_keys = 0\n",
    "    unmatched_keys = 0\n",
    "    superthanker_count = 0\n",
    "    thanker_count = 0\n",
    "    anon_ids = []\n",
    "    \n",
    "    with open(os.path.join(data_dir, \"historical_survey_merged\", lang + \"-merged-20190729.csv\")) as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            if(row['anonymized_id'] in id_key.keys()):\n",
    "                matched_keys += 1\n",
    "                \n",
    "                ##tally up the results\n",
    "                anon_id = row['anonymized_id']\n",
    "                user_name = id_key[anon_id]['user_name']\n",
    "                user_email    = id_key[anon_id]['user_email']\n",
    "                if user_name in superthankers[lang] or user_name in liason_usernames:\n",
    "                    superthanker_count += 1\n",
    "                else:\n",
    "                    thanker_count += 1\n",
    "                    thanker_ids.append({\n",
    "                        \"user_name\":user_name,\n",
    "                        \"user_email\": user_email,\n",
    "                        \"anon_id\": anon_id,\n",
    "                        \"lang\": lang\n",
    "                    })\n",
    "                    anon_ids.append(anon_id)\n",
    "            else:\n",
    "                unmatched_keys += 1\n",
    "                print(row['anonymized_id'])\n",
    "        print(\"{0} PARTICIPATION COUNTS\".format(lang))\n",
    "        print(\"\")\n",
    "        print(\"  {0} thankers\".format(thanker_count))\n",
    "        print(\"  {0} superthankers (that consented)\".format(superthanker_count))\n",
    "                \n",
    "        print(\"  DIAGNOSTIC:\")\n",
    "        print(\"    {0} Matched Keys: {1}\".format( lang, matched_keys))\n",
    "        print(\"    {0} Unmatched Keys: {1}\".format( lang, unmatched_keys))\n",
    "        print(\"    {0} Unique anonymized IDs\".format(len(set(anon_ids))))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Anonymized IDs of Thankers For Recruitment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411 total thankers in the study\n"
     ]
    }
   ],
   "source": [
    "print(\"{0} total thankers in the study\".format(len(thanker_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(thanker_ids).to_csv(os.path.join(data_dir,\n",
    "        \"thanker_email_recruitment\", \"thanker_recruitment_emails-07.29.2019.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
