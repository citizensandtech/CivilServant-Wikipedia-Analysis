{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, datetime, csv\n",
    "import pprint\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt   # Matplotlib for plotting\n",
    "from dateutil import parser\n",
    "\n",
    "languages = [\"fr\",\"es\",\"ru\",\"pt\",\"pl\",\"nl\",\"fa\",\"he\",\"ar\",\"sv\",\"cs\",\"hu\",\"fi\",\"ro\",\"et\",\"tr\"]\n",
    "cutoff_date_wiki = 20171101000000\n",
    "cutoff_date_dt = parser.parse('2017-11-01 00:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Per-Language Dataset of Users Who Hadn't Received Thanks or Love by Nov 2017\n",
    "The purpose of this script is to create a per-language dataset of users who hadn't received thanks or love by Nov 2017. We do this by taking a dataset of all historical thanks or love per language, look at all thanks/love that had been received by the end of October 2017, and then create the subset of user ids that made at least one revision in November 2017 that weren't in that dataset, per language.\n",
    "\n",
    "This project relies on the following PAWS scripts:\n",
    "* [Querying Unique Editors for a Given Month in Wikipedia](https://paws.wmflabs.org/paws/user/Rubberpaw/notebooks/Accessing%20A%20Month%20of%20Unique%20Editors%20from%20a%20Wikipedia.ipynb#)\n",
    "* Max's code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Per-Language Datset of Editors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 81343 rows, discarded 0 rows\n"
     ]
    }
   ],
   "source": [
    "## SET UP THE DICT OF EDITORS\n",
    "nov_editors = {}\n",
    "for lang in languages:\n",
    "    nov_editors[lang]  = {}\n",
    "    \n",
    "rows_processed = 0\n",
    "rows_discarded = 0    \n",
    "\n",
    "with open(\"data/unique_editors_by_language_nov-2017.csv\") as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        language = row['language'].replace(\"wiki_p\", \"\")\n",
    "        row['newcomer'] = False\n",
    "        if(language in languages):\n",
    "            try:\n",
    "                if int(row['user_registration'].replace(\"b'\",\"\").replace(\"'\",\"\"))>cutoff_date_wiki:\n",
    "                    row['newcomer'] = True\n",
    "            except:\n",
    "                pass\n",
    "            nov_editors[language][row['rev_user']] = row\n",
    "            rows_processed += 1\n",
    "        else:\n",
    "            rows_discarded += 1\n",
    "print(\"Processed {0} rows, discarded {1} rows\".format(rows_processed, rows_discarded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Per-Language Dataset of Thanks and Love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 557258 rows, discarded 0 rows.\n",
      "Languages processed: {'es', 'ar', 'pt', 'tr', 'hu', 'sv', 'fa', 'he'}\n"
     ]
    }
   ],
   "source": [
    "thanks_dataset_sent = {}\n",
    "thanks_dataset_received = {}\n",
    "love_dataset_sent = {}\n",
    "love_dataset_received = {}\n",
    "for lang in languages:\n",
    "    thanks_dataset_sent[lang] = set()\n",
    "    thanks_dataset_received[lang] = set()\n",
    "    love_dataset_sent[lang] = set()\n",
    "    love_dataset_received[lang] = set()\n",
    "\n",
    "rows_processed = 0\n",
    "rows_discarded = 0\n",
    "languages_processed = set()\n",
    "    \n",
    "with open(\"data/gratitude_20180629.csv\") as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        language = row['lang']\n",
    "        languages_processed.add(language)\n",
    "        if(language in languages):\n",
    "            if(parser.parse(row['timestamp'])>= cutoff_date_dt):\n",
    "                continue\n",
    "            if(row['thanklove']=='thank'):\n",
    "                thanks_dataset_sent[language].add(row['sender_id'])\n",
    "                thanks_dataset_received[language].add(row['receiver_id'])\n",
    "            else:\n",
    "                love_dataset_sent[language].add(row['sender_id'])\n",
    "                love_dataset_received[language].add(row['receiver_id'])\n",
    "            rows_processed += 1\n",
    "        else:\n",
    "            rows_discarded += 1\n",
    "print(\"Processed {0} rows, discarded {1} rows.\".format(rows_processed, rows_discarded))\n",
    "print(\"Languages processed: {0}\".format(languages_processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of November accounts eligible for receiving thanks or love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39404 editors processed\n"
     ]
    }
   ],
   "source": [
    "eligible_accounts = {}\n",
    "editors_processed = 0\n",
    "for lang in list(languages_processed):\n",
    "    eligible_accounts[lang] = {'love_not_sent':[],\n",
    "                               'love_not_sent_newcomers':[],\n",
    "                               'love_not_received':[],\n",
    "                               'love_not_received_newcomers':[],\n",
    "                               'thanks_not_sent':[],\n",
    "                               'thanks_not_sent_newcomers':[],\n",
    "                               'thanks_not_received':[],\n",
    "                               'thanks_not_received_newcomers':[]}\n",
    "    \n",
    "    for key, row in nov_editors[lang].items():\n",
    "        if key not in thanks_dataset_sent[lang]:\n",
    "            eligible_accounts[lang]['thanks_not_sent'].append(row)\n",
    "            if(row['newcomer']):\n",
    "                eligible_accounts[lang]['thanks_not_sent_newcomers'].append(row)\n",
    "        if key not in thanks_dataset_received[lang]:\n",
    "            eligible_accounts[lang]['thanks_not_received'].append(row)\n",
    "            if(row['newcomer']):\n",
    "                eligible_accounts[lang]['thanks_not_received_newcomers'].append(row)\n",
    "        if key not in love_dataset_sent[lang]:\n",
    "            eligible_accounts[lang]['love_not_sent'].append(row)\n",
    "            if(row['newcomer']):\n",
    "                eligible_accounts[lang]['love_not_sent_newcomers'].append(row)\n",
    "        if key not in love_dataset_received[lang]:\n",
    "            eligible_accounts[lang]['love_not_received'].append(row)\n",
    "            if(row['newcomer']):\n",
    "                eligible_accounts[lang]['love_not_received_newcomers'].append(row)\n",
    "        editors_processed += 1\n",
    "    \n",
    "print(\"{0} editors processed\".format(editors_processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a single dataframe with the sample for all available languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_language_thanks_love = []\n",
    "for lang in list(languages_processed):\n",
    "    row = {\"lang\": lang}\n",
    "    for key in eligible_accounts[lang].keys():\n",
    "        row[key] = len(eligible_accounts[lang][key])\n",
    "    row['total_editors'] = len(nov_editors[lang])\n",
    "    all_language_thanks_love.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_language_thanks_love).to_csv(\"data/gratitude_study_eligible_account_counts-Nov-2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lang': 'es',\n",
       "  'love_not_received': 16563,\n",
       "  'love_not_received_newcomers': 7253,\n",
       "  'love_not_sent': 16751,\n",
       "  'love_not_sent_newcomers': 7253,\n",
       "  'thanks_not_received': 14346,\n",
       "  'thanks_not_received_newcomers': 7253,\n",
       "  'thanks_not_sent': 14953,\n",
       "  'thanks_not_sent_newcomers': 7253,\n",
       "  'total_editors': 16946},\n",
       " {'lang': 'ar',\n",
       "  'love_not_received': 3861,\n",
       "  'love_not_received_newcomers': 2241,\n",
       "  'love_not_sent': 3946,\n",
       "  'love_not_sent_newcomers': 2241,\n",
       "  'thanks_not_received': 3533,\n",
       "  'thanks_not_received_newcomers': 2241,\n",
       "  'thanks_not_sent': 3694,\n",
       "  'thanks_not_sent_newcomers': 2241,\n",
       "  'total_editors': 4138},\n",
       " {'lang': 'pt',\n",
       "  'love_not_received': 5511,\n",
       "  'love_not_received_newcomers': 2137,\n",
       "  'love_not_sent': 5636,\n",
       "  'love_not_sent_newcomers': 2137,\n",
       "  'thanks_not_received': 4576,\n",
       "  'thanks_not_received_newcomers': 2137,\n",
       "  'thanks_not_sent': 5033,\n",
       "  'thanks_not_sent_newcomers': 2137,\n",
       "  'total_editors': 5893},\n",
       " {'lang': 'tr',\n",
       "  'love_not_received': 709,\n",
       "  'love_not_received_newcomers': 199,\n",
       "  'love_not_sent': 741,\n",
       "  'love_not_sent_newcomers': 199,\n",
       "  'thanks_not_received': 582,\n",
       "  'thanks_not_received_newcomers': 199,\n",
       "  'thanks_not_sent': 631,\n",
       "  'thanks_not_sent_newcomers': 199,\n",
       "  'total_editors': 795},\n",
       " {'lang': 'hu',\n",
       "  'love_not_received': 1591,\n",
       "  'love_not_received_newcomers': 448,\n",
       "  'love_not_sent': 1659,\n",
       "  'love_not_sent_newcomers': 448,\n",
       "  'thanks_not_received': 1254,\n",
       "  'thanks_not_received_newcomers': 448,\n",
       "  'thanks_not_sent': 1370,\n",
       "  'thanks_not_sent_newcomers': 448,\n",
       "  'total_editors': 1716},\n",
       " {'lang': 'sv',\n",
       "  'love_not_received': 2696,\n",
       "  'love_not_received_newcomers': 922,\n",
       "  'love_not_sent': 2763,\n",
       "  'love_not_sent_newcomers': 922,\n",
       "  'thanks_not_received': 2089,\n",
       "  'thanks_not_received_newcomers': 922,\n",
       "  'thanks_not_sent': 2314,\n",
       "  'thanks_not_sent_newcomers': 922,\n",
       "  'total_editors': 2840},\n",
       " {'lang': 'fa',\n",
       "  'love_not_received': 3988,\n",
       "  'love_not_received_newcomers': 2011,\n",
       "  'love_not_sent': 4054,\n",
       "  'love_not_sent_newcomers': 2011,\n",
       "  'thanks_not_received': 3641,\n",
       "  'thanks_not_received_newcomers': 2011,\n",
       "  'thanks_not_sent': 3747,\n",
       "  'thanks_not_sent_newcomers': 2011,\n",
       "  'total_editors': 4244},\n",
       " {'lang': 'he',\n",
       "  'love_not_received': 2501,\n",
       "  'love_not_received_newcomers': 784,\n",
       "  'love_not_sent': 2656,\n",
       "  'love_not_sent_newcomers': 784,\n",
       "  'thanks_not_received': 1894,\n",
       "  'thanks_not_received_newcomers': 784,\n",
       "  'thanks_not_sent': 2203,\n",
       "  'thanks_not_sent_newcomers': 784,\n",
       "  'total_editors': 2832}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counter([x['newcomer'] for x in nov_editors[lang].values()])\n",
    "all_language_thanks_love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
